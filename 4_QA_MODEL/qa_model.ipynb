{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**QA Model**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import pymupdf\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "import chromadb\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df = pd.read_csv(\"../1_WEB_SCRAPING/crawl_outputs/biorxiv_genomics_papers_7070.csv\")\n",
    "print(f\"Loaded {len(papers_df)} papers from CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get text from HTML abstract\n",
    "def get_abstract(paper_url):\n",
    "    time.sleep(1)\n",
    "    response = requests.get(paper_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    if response.status_code != 200:\n",
    "        return \"Abstract not available\"\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    abstract_section = soup.find(\"div\", class_=\"abstract\")\n",
    "    return abstract_section.text.strip() if abstract_section else \"Abstract not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BioBERT model/tokenizer\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings\n",
    "def get_embedding(text, max_length=512):\n",
    "    inputs = tokenizer(text[:max_length], return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = chroma_client.get_or_create_collection(\"genomics_papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process papers\n",
    "# for _, paper in tqdm(papers_df.iterrows(), total=len(papers_df), desc=\"Processing Papers\"):\n",
    "#     abstract = get_abstract(paper[\"Paper_URL\"])\n",
    "#     text_content = abstract if abstract != \"Abstract not found.\" else \"\"\n",
    "#     embedding = get_embedding(text_content)\n",
    "#     collection.add(\n",
    "#         ids=[paper[\"DOI\"]],\n",
    "#         embeddings=[embedding.tolist()],\n",
    "#         metadatas=[{\"Title\": paper[\"Title\"], \"Authors\": paper[\"Authors\"], \"Date\": paper[\"Date\"], \"URL\": paper[\"Paper_URL\"]}]\n",
    "#     )\n",
    "\n",
    "batch_size = 25  # Adjust based on your system capacity\n",
    "batch = []\n",
    "\n",
    "for _, paper in tqdm(papers_df.iterrows(), total=len(papers_df), desc=\"Processing Papers\"):\n",
    "    abstract = get_abstract(paper[\"Paper_URL\"])\n",
    "    if abstract == \"Abstract not found.\":\n",
    "        continue\n",
    "    embedding = get_embedding(abstract)\n",
    "    \n",
    "    batch.append((paper[\"DOI\"], embedding.tolist(), {\n",
    "        \"Title\": paper[\"Title\"], \n",
    "        \"Authors\": paper[\"Authors\"], \n",
    "        \"Date\": paper[\"Date\"], \n",
    "        \"URL\": paper[\"Paper_URL\"]\n",
    "    }))\n",
    "   \n",
    "    # Process in batches\n",
    "    if len(batch) >= batch_size:\n",
    "        ids, embeddings, metadata = zip(*batch)\n",
    "        collection.add(ids=list(ids), embeddings=list(embeddings), metadatas=list(metadata))\n",
    "        batch = []  # Clear the batch to free memory\n",
    "\n",
    "# Insert any remaining data\n",
    "if batch:\n",
    "    ids, embeddings, metadata = zip(*batch)\n",
    "    collection.add(ids=list(ids), embeddings=list(embeddings), metadatas=list(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… All papers processed and stored in ChromaDB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RAG model\n",
    "model_name = \"facebook/rag-token-base\"\n",
    "rag_tokenizer = RagTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "rag_retriever = RagRetriever.from_pretrained(model_name, indexed_dataset=None, trust_remote_code=True)\n",
    "rag_model = RagSequenceForGeneration.from_pretrained(model_name, retriever=rag_retriever, trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for RAG-based Q&A\n",
    "def retrieve_and_answer(query):\n",
    "    query_embedding = get_embedding(query)\n",
    "    results = collection.query(query_embeddings=[query_embedding.tolist()], n_results=3)\n",
    "    context = \" \".join([doc[\"metadatas\"][\"Title\"] + \" \" + doc[\"metadatas\"][\"URL\"] for doc in results[\"documents\"]])\n",
    "    \n",
    "    input_text = f\"question: {query} context: {context}\"\n",
    "    inputs = rag_tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    output_ids = rag_model.generate(**inputs)\n",
    "    return rag_tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What are the key advancements in CRISPR technology?\",\n",
    "    \"How does gene editing using CRISPR/Cas9 work?\",\n",
    "    \"What are the recent discoveries in cancer genomics?\",\n",
    "    \"What is the role of long non- coding RNAs in gene regulation?\",\n",
    "    \"What are the ethical concerns sorrounding gene editing?\",\n",
    "    \"How is genome sequencing used in personalized medicine?\",\n",
    "    \"What are the most commonly studied human genome variations?\",\n",
    "    \"What is epigenetic regulation and its significance in genomics?\",\n",
    "    \"How are CRISPR and gene therapy related?\",\n",
    "    \"What is the significance of genomic data in disease prediction?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the RAG response for the queries\n",
    "for query in queries:\n",
    "    answer = retrieve_and_answer(query)\n",
    "    print(f\"Query: {query}\\nAnswer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "os.remove(\"temp.pdf\")\n",
    "chroma_client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
